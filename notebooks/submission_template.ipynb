{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Submission\n",
    "\n",
    "This section will contain a reusable utility function to submit the predictions to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q matplotlib pandas numpy plotnine scikit-learn xgboost imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'\n",
    "TEST_CSV = DATA_DIR + 'test.csv'\n",
    "TRAIN_CSV = DATA_DIR + 'train.csv'\n",
    "TEST_CSV = DATA_DIR + 'test.csv'\n",
    "\n",
    "TARGET_COLUMN = \"Target\"\n",
    "ID_COLUMN = \"Id\"\n",
    "HOUSE_HOLD_ID_COLUMN = \"idhogar\"\n",
    "\n",
    "DEFAULT_RANDOM_STATE = 369\n",
    "DEFAULT_TEST_SIZE = 0.3\n",
    "DEFAULT_VALIDATION_SIZE = 0.3\n",
    "DEFAULT_CROSS_VALIDATION = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def fill_and_encode(data):\n",
    "    num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = data.select_dtypes(include=['object', 'bool']).columns  \n",
    "\n",
    "    num_transformer = SimpleImputer(strategy='median') \n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ])\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "    fit_data = pipeline.fit_transform(data)\n",
    "    \n",
    "    onehot_encoder = pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "    onehot_cols = [f\"{col}_{val}\" for col, vals in zip(cat_cols, onehot_encoder.categories_) for val in vals]\n",
    "    feature_names = np.append(num_cols, onehot_cols)\n",
    "    return pd.DataFrame(fit_data, columns = feature_names)\n",
    "\n",
    "def remove_columns(data):\n",
    "    cols_to_remove = [ ID_COLUMN, TARGET_COLUMN, HOUSE_HOLD_ID_COLUMN ]\n",
    "    for col in cols_to_remove:\n",
    "        if col in data.columns:\n",
    "            data = data.drop(columns = col)\n",
    "    return data\n",
    "\n",
    "def prepare(csv_path = None, data = None):\n",
    "    if csv_path is None and data is None:\n",
    "        raise ValueError(\"Either csv_path or data must be provided\")\n",
    "    if csv_path is not None and data is not None:\n",
    "        raise ValueError(\"Only one of csv_path or data must be provided\")\n",
    "    raw_data = pd.read_csv(csv_path) if csv_path is not None else deepcopy(data)\n",
    "    raw_data = remove_columns(raw_data)\n",
    "    return fill_and_encode(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    train_x, \n",
    "    train_y, \n",
    "    param_grid = None, \n",
    "    boosting = 'not-xgb',\n",
    "    encoder = None,\n",
    "    test_size=DEFAULT_VALIDATION_SIZE, \n",
    "    cv = DEFAULT_CROSS_VALIDATION):\n",
    "\n",
    "    if boosting == 'xgb' and encoder is None:\n",
    "        raise ValueError(\"encoder must be provided for xgb boosting\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=test_size, random_state=DEFAULT_RANDOM_STATE)\n",
    "\n",
    "    if param_grid is not None:\n",
    "        model = GridSearchCV(model, param_grid, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "    model.fit(X_train, y_train if boosting != 'xgb' else encoder.fit_transform(y_train))\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = predictions if boosting != 'xgb' else encoder.inverse_transform(predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO if xgboost then add prediction output transformation and encoder\n",
    "def submit(model):\n",
    "    test_data = pd.read_csv(TEST_CSV)\n",
    "    pred_input = prepare(TEST_CSV)\n",
    "    predictions = model.predict(pred_input)\n",
    "    submission_df = pd.DataFrame({ID_COLUMN: test_data[ID_COLUMN], TARGET_COLUMN: predictions})\n",
    "    df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
