{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Submission\n",
    "\n",
    "This section will contain a reusable utility function to submit the predictions to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas numpy scikit-learn xgboost imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = '/kaggle/input/costa-rican-household-poverty-prediction/'\n",
    "DATA_DIR = '../data/'\n",
    "\n",
    "TEST_CSV = DATA_DIR + 'test.csv'\n",
    "TRAIN_CSV = DATA_DIR + 'train.csv'\n",
    "TEST_CSV = DATA_DIR + 'test.csv'\n",
    "\n",
    "TARGET_COLUMN = \"Target\"\n",
    "ID_COLUMN = \"Id\"\n",
    "HOUSE_HOLD_ID_COLUMN = \"idhogar\"\n",
    "\n",
    "DEFAULT_RANDOM_STATE = 369\n",
    "DEFAULT_TEST_SIZE = 0.3\n",
    "DEFAULT_VALIDATION_SIZE = 0.3\n",
    "DEFAULT_CROSS_VALIDATION = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from copy import deepcopy\n",
    "\n",
    "pipeline = None\n",
    "\n",
    "def fill_and_encode(data, fit=False):\n",
    "    global pipeline\n",
    "\n",
    "    num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    cat_cols = data.select_dtypes(include=['object', 'bool']).columns  \n",
    "\n",
    "    num_transformer = SimpleImputer(strategy='median') \n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ])\n",
    "\n",
    "    if pipeline is None or fit:\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "        fit_data = pipeline.fit_transform(data)\n",
    "    else:\n",
    "        fit_data = pipeline.transform(data)\n",
    "    \n",
    "    onehot_encoder = pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "    onehot_cols = [f\"{col}_{val}\" for col, vals in zip(cat_cols, onehot_encoder.categories_) for val in vals]\n",
    "    feature_names = np.append(num_cols, onehot_cols)\n",
    "    return pd.DataFrame(fit_data, columns = feature_names)\n",
    "\n",
    "def remove_columns(data):\n",
    "    cols_to_remove = [ ID_COLUMN, TARGET_COLUMN, HOUSE_HOLD_ID_COLUMN ]\n",
    "    for col in cols_to_remove:\n",
    "        if col in data.columns:\n",
    "            data = data.drop(columns = col)\n",
    "    return data\n",
    "\n",
    "def prepare(csv_path = None, data = None):\n",
    "    if csv_path is None and data is None:\n",
    "        raise ValueError(\"Either csv_path or data must be provided\")\n",
    "    if csv_path is not None and data is not None:\n",
    "        raise ValueError(\"Only one of csv_path or data must be provided\")\n",
    "    raw_data = pd.read_csv(csv_path) if csv_path is not None else deepcopy(data)\n",
    "    raw_data = remove_columns(raw_data)\n",
    "    return fill_and_encode(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    train_x, \n",
    "    train_y, \n",
    "    param_grid = None, \n",
    "    boosting = 'not-xgb',\n",
    "    encoder = None,\n",
    "    test_size=DEFAULT_VALIDATION_SIZE, \n",
    "    cv = DEFAULT_CROSS_VALIDATION):\n",
    "\n",
    "    if boosting == 'xgb' and encoder is None:\n",
    "        raise ValueError(\"encoder must be provided for xgb boosting\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=test_size, random_state=DEFAULT_RANDOM_STATE)\n",
    "\n",
    "    if param_grid is not None:\n",
    "        model = GridSearchCV(model, param_grid, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "    model.fit(X_train, y_train if boosting != 'xgb' else encoder.fit_transform(y_train))\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = predictions if boosting != 'xgb' else encoder.inverse_transform(predictions)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "    return model, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def oversample(X, y):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    return ros.fit_resample(X, y)\n",
    "\n",
    "def undersample(X, y):\n",
    "    ros = RandomUnderSampler(random_state=0)\n",
    "    return ros.fit_resample(X, y)\n",
    "\n",
    "def smotsample(X, y):\n",
    "    ros = SMOTETomek(sampling_strategy='auto')\n",
    "    return ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(model, xgb_encoder = None):\n",
    "    test_data = pd.read_csv(TEST_CSV)\n",
    "    pred_input = prepare(TEST_CSV)\n",
    "    predictions = model.predict(pred_input)\n",
    "    predictions = predictions if xgb_encoder is None else xgb_encoder.inverse_transform(predictions)\n",
    "    submission_df = pd.DataFrame({ID_COLUMN: test_data[ID_COLUMN], TARGET_COLUMN: predictions})\n",
    "    submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv(TRAIN_CSV)\n",
    "TARGET = csv_data[TARGET_COLUMN]\n",
    "DATA = prepare(data=csv_data)\n",
    "TRAINING_FEATURES = DATA.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(DATA, TARGET, test_size=DEFAULT_TEST_SIZE, random_state=DEFAULT_RANDOM_STATE)\n",
    "oversampled_X, oversampled_y = oversample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'estimator__max_depth': [10], 'estimator__min_samples_leaf': [5], 'learning_rate': [0.5]}\n",
    "gs, _ = train_model(AdaBoostClassifier(estimator=DecisionTreeClassifier()), oversampled_X, oversampled_y, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_params = {'n_estimators': [300], 'min_samples_leaf': [5], 'max_depth': [10], 'learning_rate': [0.5] }\n",
    "gb_result = train_model(GradientBoostingClassifier(), oversampled_X, oversampled_y, param_grid=g_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "x_params = {\n",
    "    'objective': ['multi:logistic'], \n",
    "    'num_class': [4], \n",
    "    'n_estimators': [100], \n",
    "    'max_depth': [10], \n",
    "    'learning_rate': [0.1], \n",
    "    'eval_metric': ['merror']\n",
    "}\n",
    "\n",
    "xgb_result = train_model(\n",
    "    XGBClassifier(), \n",
    "    oversampled_X, \n",
    "    oversampled_y, \n",
    "    param_grid=x_params, \n",
    "    boosting='xgb', \n",
    "    encoder=le,\n",
    ")\n",
    "\n",
    "submit(xgb_result[0], le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9747565096402305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(gs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
